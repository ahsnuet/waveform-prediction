{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebef34a-b387-44eb-b7aa-a00aa5e201d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup for multiple output display\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89745583-1609-4642-a785-e947d11322a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import glob\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.optimizers import *\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.compose import make_column_transformer\n",
    "from  sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, LabelEncoder # Convert data to oneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, MaxAbsScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c899bd39-4a11-488b-800f-eea0711e38d3",
   "metadata": {},
   "source": [
    "# Set up the GPU device [optional]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66797044-830b-42e8-86d9-23351a192462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A tensor environment should be setup for GPU, read instructions for details.\n",
    "# Set up the GPU device\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "physical_devices\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "# Check if GPU is available\n",
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found')\n",
    "else:\n",
    "    print(\"No GPU found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d5b857-4a6e-4e73-be2d-280031206c89",
   "metadata": {},
   "source": [
    "# Read the train and test dataset files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f95ff6d-f55d-4bd8-80d9-b041110378bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataFilePath = \"data/train_dataset.csv\";\n",
    "testDataFilePath = \"data/test_dataset.csv\";\n",
    "coDataFilePath = \"data/unseen_test_dataset.csv\";\n",
    "\n",
    "df_train = pd.read_csv(trainDataFilePath) # Read train data CSV file\n",
    "df_train = shuffle(df_train)\n",
    "df_train.head()\n",
    "\n",
    "df_test = pd.read_csv(testDataFilePath) # Read test data CSV file\n",
    "df_test.head()\n",
    "\n",
    "df_co = pd.read_csv(coDataFilePath) # Read cohort test data CSV file\n",
    "df_co.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af85aed9-d6f5-4878-a672-e2f86ecbe428",
   "metadata": {},
   "source": [
    "# Checking class counts in respective datasets [for verification]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079a395f-e29d-443e-8692-2a9f0c46fa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = df_train['Jettable'].value_counts() #Training Data Class Count\n",
    "print (\"Train: \",class_counts.index,\"| \", class_counts.values)\n",
    "\n",
    "class_counts = df_test['Jettable'].value_counts() #Test Data Class Count\n",
    "print (\"Test: \",class_counts.index,\"| \", class_counts.values)\n",
    "\n",
    "class_counts = df_co['Jettable'].value_counts() #Test Data Class Count\n",
    "print (\"Cohort: \",class_counts.index,\"| \", class_counts.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d44fde8-1b4b-46af-9c50-b9c5c6b5047f",
   "metadata": {},
   "source": [
    "# Drop the unnecessary feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b951ff-2cc3-44d7-8574-b29b2703a106",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(['MaterialName','Printer','Re','We','Ca','Z','Oh','Bo'],axis=1)\n",
    "df_test = df_test.drop(['MaterialName','Printer','Re','We','Ca','Z','Oh','Bo'],axis=1)\n",
    "df_co = df_co.drop(['MaterialName','Printer','Re','We','Ca','Z','Oh','Bo'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e0cf02-5f22-4b81-a9db-7d9c47deffb3",
   "metadata": {},
   "source": [
    "# Check for NA values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29b66cb-b891-49f3-b690-b0b7fa0ed60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_nan_per_column = df_train.isnull().any(axis=0)\n",
    "print(has_nan_per_column)\n",
    "\n",
    "print ('--------------------------------------------------')\n",
    "has_nan_per_column = df_test.isnull().any(axis=0)\n",
    "print(has_nan_per_column)\n",
    "\n",
    "print ('--------------------------------------------------')\n",
    "has_nan_per_column = df_co.isnull().any(axis=0)\n",
    "print(has_nan_per_column)\n",
    "\n",
    "# replace the na values with zero\n",
    "df_train = df_train.fillna(0)\n",
    "df_test = df_test.fillna(0)\n",
    "df_co = df_co.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40606391-c742-4ad3-9cf8-8a09c256ec61",
   "metadata": {},
   "source": [
    "# Data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbec397-16dc-45ad-884f-a7ea54c63808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate features and target variable\n",
    "df_train_num = df_train.drop(['PulseDuration','Voltage','Trise','Tfall','Jettable','WaveformType'], axis=1) # target columns are also dropped\n",
    "df_test_num = df_test.drop(['PulseDuration','Voltage','Trise','Tfall','Jettable','WaveformType'], axis=1)\n",
    "df_co_num = df_co.drop(['PulseDuration','Voltage','Trise','Tfall','Jettable','WaveformType'], axis=1)\n",
    "\n",
    "# save non-numeric columns\n",
    "non_numeric_cols_train = df_train.select_dtypes(exclude='number').columns\n",
    "non_numeric_cols_test = df_test.select_dtypes(exclude='number').columns\n",
    "non_numeric_cols_co = df_co.select_dtypes(exclude='number').columns\n",
    "\n",
    "# apply MinMaxScaler to all numeric columns except target column\n",
    "scaler = MinMaxScaler()\n",
    "df_train_num_scaled = scaler.fit_transform(df_train_num)\n",
    "df_test_num_scaled = scaler.transform(df_test_num)\n",
    "df_co_num_scaled = scaler.transform(df_co_num)\n",
    "\n",
    "# replace the original numeric columns with scaled data\n",
    "df_train[df_train_num.columns] = df_train_num_scaled\n",
    "df_test[df_test_num.columns] = df_test_num_scaled\n",
    "df_co[df_co_num.columns] = df_co_num_scaled\n",
    "\n",
    "# restore non-numeric columns\n",
    "df_train[non_numeric_cols_train] = df_train[non_numeric_cols_train]\n",
    "df_test[non_numeric_cols_test] = df_test[non_numeric_cols_test]\n",
    "df_co[non_numeric_cols_co] = df_co[non_numeric_cols_co]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a2f0f2-e9c6-4343-8b33-c0783346b594",
   "metadata": {},
   "source": [
    "# Applying the Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ffbf0d-3cdf-4217-a63e-643411e68b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_column(df_train, df_test, df_co, column_name):\n",
    "    # Select the column by name\n",
    "    train_selected_column = df_train[column_name]\n",
    "    test_selected_column = df_test[column_name]\n",
    "    co_selected_column = df_co[column_name]\n",
    "\n",
    "    # Initialize the label encoder\n",
    "    encoder = LabelEncoder()\n",
    "\n",
    "    # Convert string values to numerical values using the encoder\n",
    "    train_encoded_values = encoder.fit_transform(train_selected_column)\n",
    "    test_encoded_values = encoder.transform(test_selected_column)\n",
    "    co_encoded_values = encoder.transform(co_selected_column)\n",
    "\n",
    "    # Replace the original column with the encoded values\n",
    "    df_train[column_name] = train_encoded_values\n",
    "    df_test[column_name] = test_encoded_values\n",
    "    df_co[column_name] = co_encoded_values\n",
    "\n",
    "    # Get the categories and their corresponding labels\n",
    "    categories = encoder.classes_\n",
    "    labels = encoder.transform(categories)\n",
    "\n",
    "    # Print the categories and labels\n",
    "    for category, label in zip(categories, labels):\n",
    "        print(f\"{category} -> {label}\")\n",
    "\n",
    "    return categories, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2522ec1-ad13-4809-b715-7fc5aaff3930",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_column(df_train, df_test, df_co, 'Jettable')\n",
    "encode_column(df_train, df_test, df_co, 'WaveformType')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ccfaa5-39f5-40b9-9b03-7d7bff1b4d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train.drop(['PulseDuration','Voltage','Trise','Tfall'],axis=1) \n",
    "y_train = df_train[['PulseDuration','Voltage','Trise','Tfall']] \n",
    "\n",
    "x_test = df_test.drop(['PulseDuration','Voltage','Trise','Tfall'],axis=1)\n",
    "y_test = df_test[['PulseDuration','Voltage','Trise','Tfall']] \n",
    "\n",
    "\n",
    "x_co = df_co.drop(['PulseDuration','Voltage','Trise','Tfall'],axis=1)\n",
    "y_co = df_co[['PulseDuration','Voltage','Trise','Tfall']] \n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train,\n",
    "                                                  y_train,\n",
    "                                                  test_size=ratioTestTrain,\n",
    "                                                  random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c83b1a7-b5b2-414b-a225-d38b24d1b063",
   "metadata": {},
   "source": [
    "# Setup models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8ae6b4-6ad2-4792-bc17-c7494e9233fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "\n",
    "    inputs = Input(input_shape)\n",
    "    x = Dense(100, activation='relu')(inputs) \n",
    "    x = Dense(300, activation='relu')(x) \n",
    "    x = Dense(500, activation='relu')(x) \n",
    "    x = Dense(300, activation='relu')(x)\n",
    "    x = Dense(100, activation='relu')(x)\n",
    "    x = Flatten()(x)\n",
    "    output = Dense(y_train.shape[1], activation='linear')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb29aa09-98b4-47c4-8753-1864a932a470",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainTotalColumns = len(df_train.columns)-4; #total number of columns in training data CSV file [total columns-number of target columns]\n",
    "ratioTestTrain = 0.1; # ratio of the train/validation dataset\n",
    "modelInputShapeParam = trainTotalColumns; # input shape parameter for NN model with Keras\n",
    "batch_size = 3\n",
    "epochs = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daae8570-5637-4b04-bea0-76b064cf00d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model((modelInputShapeParam, 1)) # input shape parameter for the model\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "callbacks = [\n",
    "             keras.callbacks.ModelCheckpoint('model_trained_weights.h5',\n",
    "                                             save_best_only=True,\n",
    "                                             monitor='val_loss'),\n",
    "             keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                               factor=0.3,\n",
    "                                               patience=100,\n",
    "                                               ),\n",
    "             keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                           patience=300,\n",
    "                                           verbose=1),\n",
    "             tf.keras.callbacks.CSVLogger( 'trans_History.csv', separator=\",\", append=True)\n",
    "             ]\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fb44a2-aae1-49e0-8117-960aa043d9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = False \n",
    "\n",
    "if Train == True:\n",
    "    # Train the model with GPU acceleration\n",
    "    with tf.device('/GPU:0'):    \n",
    "        history = model.fit(x_train, y_train,\n",
    "                            batch_size=batch_size, epochs=epochs, verbose=2,\n",
    "                            validation_data=(x_val, y_val),\n",
    "                            shuffle=True, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5817c5-48b1-4777-90fb-b396361b1678",
   "metadata": {},
   "source": [
    "# Model's training and validation plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5957690-9f87-46e9-b97b-c2d60728c058",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ploting the training and validation of the model\n",
    "plt.plot(history.history['mae'])\n",
    "plt.plot(history.history['val_mae'])\n",
    "plt.title('Model Training and Validation MAE')\n",
    "plt.ylabel('mae')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc = 'upper left')\n",
    "plt.savefig(\"trans_Train_Val_mae.png\", dpi = 600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2accc46-cac6-4fbf-82a0-85b5bfd6e4a6",
   "metadata": {},
   "source": [
    "# Exporting results custom function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e11646-0429-4c14-a698-97312395b696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_output_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate performance metrics (RMSE, MAE, MAPE) for multiple outputs in a regression task.\n",
    "\n",
    "    Parameters:\n",
    "    y_true: The true target values for each output.\n",
    "    y_pred: The predicted target values for each output.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A dictionary (`metrics`) with performance metrics for each output and \n",
    "           a pandas DataFrame (`metrics_df`) summarizing the metrics.\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    for i, col in enumerate(y_true.columns):\n",
    "        rmse = np.sqrt(mean_squared_error(y_true[col], y_pred[:, i]))\n",
    "        mae = mean_absolute_error(y_true[col], y_pred[:, i])\n",
    "        r2 = r2_score(y_true[col], y_pred[:, i])\n",
    "        mape = np.mean(np.abs((y_true[col] - y_pred[:, i]) / y_true[col])) * 100  # Convert to percentage\n",
    "\n",
    "        # metrics[col] = {'RMSE': rmse, 'R2 Score': r2, 'MAE': mae, 'MAPE': mape}\n",
    "        metrics[col] = {'RMSE': rmse, 'MAE': mae, 'MAPE': mape}\n",
    "        print(f\"Output: {col}\")\n",
    "        print(f\"RMSE: {rmse:.6f}\")\n",
    "        # print(f\"R2 Score: {r2:.6f}\")\n",
    "        print(f\"MAE: {mae:.6f}\")\n",
    "        print(f\"MAPE: {mape:.6f}%\")  # Display MAPE as percentage\n",
    "        print()\n",
    "    \n",
    "    metrics = pd.DataFrame(metrics)\n",
    "    # print(metrics)\n",
    "    metrics_df = pd.DataFrame(metrics).T\n",
    "    print(metrics_df)\n",
    "    return metrics, metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb29713e-dadf-41c3-871f-6e5e36199350",
   "metadata": {},
   "source": [
    "# Model Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac494194-5386-4b83-ab19-1ff21bda17da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Load the trained model for Testing\n",
    "model = load_model(\"model_trained_weights.h5\")\n",
    "\n",
    "with open('model_summary.txt', 'w') as f:\n",
    "    # Redirect the print output to the file\n",
    "    model.summary(print_fn=lambda x: f.write(x + '\\n'))  # Write summary to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa026849-17c3-4449-80e6-28e7c15e517d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "\n",
    "column_names = ['PulseDuration','Voltage','Trise','Tfall']\n",
    "pd.DataFrame(y_pred, columns=column_names).to_csv('y_pred.csv')\n",
    "\n",
    "# Compute and display metrics\n",
    "output_metrics, output_metrics_df  = multi_output_metrics(y_test, y_pred)\n",
    "\n",
    "# # Append performance metrics data to file\n",
    "output_metrics.to_csv('PerformanceMetrics.csv',mode='a')\n",
    "\n",
    "# Append performance metrics data to file\n",
    "output_metrics_df.to_csv('PerformanceScores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872006e4-12e0-47f0-8e88-36e76c685a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_co)\n",
    "\n",
    "pd.DataFrame(y_pred, columns=column_names).to_csv('y_coPred.csv')\n",
    "\n",
    "# Compute and display metrics\n",
    "output_metrics, output_metrics_df = multi_output_metrics(y_co, y_pred)\n",
    "\n",
    "# Append performance metrics data to file\n",
    "output_metrics.to_csv('co_PerformanceMetrics.csv',mode='a')\n",
    "\n",
    "# Append performance metrics data to file\n",
    "output_metrics_df.to_csv('co_PerformanceScores.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
